{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qh4pjpfjgv5C"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n"
      ],
      "metadata": {
        "id": "zfAz79kIgyCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Backpropagation:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Initialize weights with random values\n",
        "        self.weights1 = np.random.randn(self.input_size, self.hidden_size)\n",
        "        self.weights2 = np.random.randn(self.hidden_size, self.output_size)\n",
        "\n",
        "        # Initialize biases with zeros\n",
        "        self.bias1 = np.zeros((1, self.hidden_size))\n",
        "        self.bias2 = np.zeros((1, self.output_size))\n",
        "\n",
        "    def forward(self, X):\n",
        "        # Forward propagation\n",
        "        self.hidden_layer = sigmoid(np.dot(X, self.weights1) + self.bias1)\n",
        "        self.output_layer = sigmoid(np.dot(self.hidden_layer, self.weights2) + self.bias2)\n",
        "        return self.output_layer\n",
        "\n",
        "    def backward(self, X, y, learning_rate):\n",
        "        # Backward propagation\n",
        "        delta2 = (self.output_layer - y) * sigmoid_derivative(self.output_layer)\n",
        "        d_weights2 = np.dot(self.hidden_layer.T, delta2)\n",
        "        d_bias2 = np.sum(delta2, axis=0)\n",
        "\n",
        "        delta1 = np.dot(delta2, self.weights2.T) * sigmoid_derivative(self.hidden_layer)\n",
        "        d_weights1 = np.dot(X.T, delta1)\n",
        "        d_bias1 = np.sum(delta1, axis=0)\n",
        "\n",
        "        # Update weights and biases\n",
        "        self.weights2 -= learning_rate * d_weights2\n",
        "        self.bias2 -= learning_rate * d_bias2\n",
        "        self.weights1 -= learning_rate * d_weights1\n",
        "        self.bias1 -= learning_rate * d_bias1\n",
        "\n",
        "    def train(self, X, y, epochs, learning_rate):\n",
        "        for epoch in range(epochs):\n",
        "            # Forward and backward propagation for each sample\n",
        "            self.forward(X)\n",
        "            self.backward(X, y, learning_rate)\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Predict the output for new inputs\n",
        "        return self.forward(X)\n"
      ],
      "metadata": {
        "id": "BeRIS1pIg2kR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the dataset\n",
        "dataset = np.array([\n",
        "    [624.00, 89.160, 89.765, 3.500, 2512.85],\n",
        "    [628.00, 93.160, 93.765, 3.500, 2583.79],\n",
        "    # ... add more rows of data\n",
        "])\n",
        "\n",
        "# Split the dataset into input (X) and output (y)\n",
        "X = dataset[:, :-1]\n",
        "y = dataset[:, -1:]\n",
        "\n",
        "# Normalize the input data if necessary\n",
        "# ...\n",
        "\n",
        "# Instantiate the Backpropagation class\n",
        "input_size = X.shape[1]\n",
        "hidden_size = 4  # Number of neurons in the hidden layer\n",
        "output_size = 1\n",
        "bp = Backpropagation(input_size, hidden_size, output_size)\n"
      ],
      "metadata": {
        "id": "rNDhnUJyg37n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000\n",
        "learning_rate = 0.1\n",
        "bp.train(X, y, epochs, learning_rate)\n"
      ],
      "metadata": {
        "id": "jtC3jniDhBrq",
        "outputId": "5e15b23b-3806-412b-f775-767303288d0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-6bb1af10151c>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-x))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare new input data for prediction\n",
        "new_data = np.array([[630.00, 94.840, 94.415, 6.500]])\n",
        "\n",
        "# Normalize the new data if necessary\n",
        "# ...\n",
        "\n",
        "# Make predictions\n",
        "prediction = bp.predict(new_data)\n",
        "print(\"Predicted output:\", prediction)\n"
      ],
      "metadata": {
        "id": "2vYgb9RhhCLY",
        "outputId": "57684a50-12ea-48c9-e889-8adf1883b6c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted output: [[1.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-6bb1af10151c>:2: RuntimeWarning: overflow encountered in exp\n",
            "  return 1 / (1 + np.exp(-x))\n"
          ]
        }
      ]
    }
  ]
}